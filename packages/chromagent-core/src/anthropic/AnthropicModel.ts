
export interface RequestTextBlock {
    type: 'text';
    text: string;
    cache_control?: {
        type: 'ephemeral';
        ttl?: '5m' | '1h';
    };
}

/**
 * Related docs: docs/specs/anthropic-messages.md
 * Contains minimal fields for the following functions only:
 * - Image
 * - Tool Call
 * - Temperature config
 * - token usage data
 */
export interface AnthropicMessageRequest {
    /** The model that will complete your prompt */
    model: string;

    /** Input messages. Each input message must be an object with a `role` and `content` */
    messages: Array<{
        role: 'user' | 'assistant';
        content: string | Array<{
            type: 'text' | 'image' | 'tool_use' | 'tool_result' | 'thinking';
            text?: string;
            thinking?: string;
            source?: {
                type: 'base64';
                media_type: 'image/jpeg' | 'image/png' | 'image/gif' | 'image/webp';
                data: string;
            };
            id?: string;
            name?: string;
            input?: Record<string, any>;
            tool_use_id?: string;
            content?: string | Array<any>;
        }>;
    }>;

    /** The maximum number of tokens to generate before stopping */
    max_tokens: number;

    /** Amount of randomness injected into the response */
    temperature?: number;

    /** System prompt */
    system?: string | RequestTextBlock[];

    /** Definitions of tools that the model may use */
    tools?: Array<{
        name: string;
        description: string;
        input_schema: {
            type: 'object';
            properties: Record<string, any>;
            required?: string[];
        };
    }>;

    /** How the model should use the provided tools */
    tool_choice?: {
        type: 'auto' | 'any' | 'tool';
        name?: string;
    };

    /** Custom text sequences that will cause the model to stop generating */
    stop_sequences?: string[];

    /** Whether to incrementally stream the response */
    stream?: boolean;
}

/**
 * Related docs: docs/specs/anthropic-messages.md
 */
export interface AnthropicMessageResponse {
    /** Unique object identifier */
    id: string;

    /** Object type - for Messages, this is always "message" */
    type: 'message';

    /** Conversational role of the generated message - this will always be "assistant" */
    role: 'assistant';

    /** Content generated by the model */
    content: Array<{
        type: 'text' | 'tool_use';
        text?: string;
        id?: string;
        name?: string;
        input?: Record<string, any>;
    }>;

    /** The model that handled the request */
    model: string;

    /** The reason that we stopped */
    stop_reason: 'end_turn' | 'max_tokens' | 'stop_sequence' | 'tool_use' | 'pause_turn' | 'refusal' | 'model_context_window_exceeded' | null;

    /** Which custom stop sequence was generated, if any */
    stop_sequence: string | null;

    /** Billing and rate-limit usage */
    usage: {
        input_tokens: number;
        output_tokens: number;
    };
}


/**
 * Related docs: docs/specs/anthropic-messages.md
 * Contains only one method to allow mapping back to anthropic compatible API
 */
export interface AnthropicModel {
    /**
     * Sends a message to the Anthropic API and returns a complete response.
     *
     * @param request - The message request containing model, messages, and other configuration
     * @returns A promise that resolves to the API response with content, model info, and usage statistics
     */
    message(request: AnthropicMessageRequest): Promise<AnthropicMessageResponse>
}